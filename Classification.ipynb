{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1599, 8)\n",
      "[[-0.56501116 -0.16590702 -0.30043    -0.03449889]\n",
      " [-0.13330822 -0.69305064  0.02430531  0.03909375]\n",
      " [-0.70389013  0.12897106  0.04204689  0.05026184]\n",
      " ...\n",
      " [ 0.13421492 -0.49899311 -0.0306054  -0.04321913]\n",
      " [ 0.35549862 -0.33717755 -0.41298198 -0.01060733]\n",
      " [-0.16576032  0.50790325 -0.06993197  0.01751129]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def loadData():\n",
    "\n",
    "    data = pd.read_csv(\"E202-COMP7117-TD01-00 - classification.csv\")\n",
    "\n",
    "    if data.isna().values.any() == True:\n",
    "        data = data.dropna()\n",
    "    \n",
    "    dataInput = data[[\"volatile acidity\", \"chlorides\", \"free sulfur dioxide\", \"total sulfur dioxide\", \n",
    "                      \"density\", \"pH\",\"sulphates\",\"alcohol\"]]\n",
    "    target = data[[\"quality\"]]\n",
    "    \n",
    "    print(dataInput.shape)\n",
    "    \n",
    "    for y in dataInput:\n",
    "        if(y == \"free sulfur dioxide\" ):\n",
    "#             print(y)\n",
    "#             print(dataInput[y][0])\n",
    "            for j in range(len(dataInput)):\n",
    "                if(dataInput[y][j] == \"High\"):\n",
    "                    dataInput.at[j, y] = 3\n",
    "                elif(dataInput[y][j] == \"Medium\"):\n",
    "                    dataInput.at[j, y] = 2\n",
    "                elif(dataInput[y][j] == \"Low\"):\n",
    "                    dataInput.at[j, y] = 1\n",
    "                else:\n",
    "                    dataInput.at[j, y] = 0\n",
    "        elif(y == \"density\"):\n",
    "#             print(y)\n",
    "#             print(dataInput[y][0])\n",
    "            for j in range(len(dataInput)):\n",
    "                if(dataInput[y][j] == \"Very High\"):\n",
    "                    dataInput.at[j, y] = 0\n",
    "                elif(dataInput[y][j] == \"High\"):\n",
    "                    dataInput.at[j, y] = 3\n",
    "                elif(dataInput[y][j] == \"Medium\"):\n",
    "                    dataInput.at[j, y] = 2\n",
    "                elif(dataInput[y][j] == \"Low\"):\n",
    "                    dataInput.at[j, y] = 1\n",
    "        elif(y == \"pH\"):\n",
    "#             print(y)\n",
    "#             print(dataInput[[y]].values[0])\n",
    "            for j in range(len(dataInput)):\n",
    "                    if(dataInput[y][j] == \"Very Basic\"):\n",
    "                        dataInput.at[j, y] = 3\n",
    "                    elif(dataInput[y][j] == \"Normal\"):\n",
    "                        dataInput.at[j, y] = 2\n",
    "                    elif(dataInput[y][j] == \"Very Acidic\"):\n",
    "                        dataInput.at[j, y] = 1\n",
    "                    else:\n",
    "                        dataInput.at[j, y] = 0\n",
    "    \n",
    "    #normalisasi\n",
    "    dataInput = MinMaxScaler().fit_transform(dataInput)\n",
    "    target = OneHotEncoder(sparse=False).fit_transform(target)\n",
    "    \n",
    "    #PCA\n",
    "    dataInput = PCA(n_components=4).fit_transform(dataInput)\n",
    "        \n",
    "    return dataInput, target\n",
    "\n",
    "\n",
    "inputData, target = loadData()\n",
    "print(inputData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "layers = {\n",
    "    \"input\": 4, #8 different kind of data\n",
    "    \"hidden\": 500,\n",
    "    \"output\": 5 # decent, fair, fine, good, great\n",
    "}\n",
    "\n",
    "weights = {\n",
    "    'input_to_hidden' : tf.Variable(tf.random_normal([layers['input'], layers['hidden']])),\n",
    "    'hidden_to_output' : tf.Variable(tf.random_normal([layers['hidden'], layers['output']]))\n",
    "}\n",
    "\n",
    "bias = {\n",
    "    'input_to_hidden' : tf.Variable(tf.random_normal([layers['hidden']])),\n",
    "    'hidden_to_output' : tf.Variable(tf.random_normal([layers['output']]))\n",
    "}\n",
    "\n",
    "inputPlaceholder = tf.placeholder(tf.float32, [None, layers[\"input\"]])\n",
    "outputPlacehlder = tf.placeholder(tf.float32, [None, layers[\"output\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1599, 4)\n",
      "(1599, 5)\n",
      "(1151, 4)\n",
      "(288, 4)\n",
      "(160, 4)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def feedForward(inputData):\n",
    "    #first\n",
    "    input_to_hidden_bias = tf.matmul(inputData, weights['input_to_hidden']) + bias['input_to_hidden']\n",
    "    activated_input_to_hidden = tf.nn.sigmoid(input_to_hidden_bias)\n",
    "    #second\n",
    "    hidden_to_output_bias = tf.matmul(activated_input_to_hidden, weights['hidden_to_output']) + bias['hidden_to_output']\n",
    "    activated_hidden_to_output = tf.nn.sigmoid(hidden_to_output_bias)\n",
    "\n",
    "    return activated_hidden_to_output\n",
    "\n",
    "predict = feedForward(inputPlaceholder)\n",
    "\n",
    "epoch = 5000\n",
    "\n",
    "error = tf.reduce_mean(0.5 * ( outputPlacehlder - predict ) ** 2)\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
    "train = optimizer.minimize(error)\n",
    "\n",
    "inputTrain, inputTest, outputTrain, outputTest = train_test_split(inputData, target, test_size=0.1)\n",
    "print(inputData.shape)\n",
    "print(target.shape)\n",
    "inputTrain, inputValidationTest, outputTrain, outputValidationTest = train_test_split(inputTrain, outputTrain, test_size=0.2)\n",
    "\n",
    "print(inputTrain.shape)\n",
    "print(inputValidationTest.shape)\n",
    "print(inputTest.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 100, loss : 0.21315479278564453\n",
      "Epoch : 200, loss : 0.21234939992427826\n",
      "Epoch : 300, loss : 0.21221476793289185\n",
      "Epoch : 400, loss : 0.21215197443962097\n",
      "Epoch : 500, loss : 0.21210670471191406\n",
      "Epoch : 600, loss : 0.2120654284954071\n",
      "Epoch : 700, loss : 0.21202245354652405\n",
      "Epoch : 800, loss : 0.21197061240673065\n",
      "Epoch : 900, loss : 0.21189771592617035\n",
      "Epoch : 1000, loss : 0.21177169680595398\n",
      "Epoch : 1100, loss : 0.21147345006465912\n",
      "Epoch : 1200, loss : 0.2102937400341034\n",
      "Epoch : 1300, loss : 0.16668279469013214\n",
      "Epoch : 1400, loss : 0.12097523361444473\n",
      "Epoch : 1500, loss : 0.12064491212368011\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    #70% of the dataset - train\n",
    "    for i in range(1, epoch + 1) :\n",
    "        train_dict = {\n",
    "            inputPlaceholder : inputTrain,\n",
    "            outputPlacehlder : outputTrain\n",
    "        }\n",
    "        sess.run(train, feed_dict = train_dict)\n",
    "\n",
    "        loss = sess.run(error, feed_dict = train_dict)\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(\"Epoch : {}, loss : {}\".format(i, loss))\n",
    "        \n",
    "        #20% of the dataset - valid\n",
    "        if i % 500 == 0:\n",
    "            \n",
    "            validation_dict = {\n",
    "                inputPlaceholder : inputValidationTest,\n",
    "                outputPlacehlder : outputValidationTest\n",
    "            }\n",
    "            sess.run(train, feed_dict = validation_dict)\n",
    "\n",
    "            Validationloss = sess.run(error, feed_dict = validation_dict)\n",
    "            \n",
    "#             print(\"Validation Epoch : {}, loss : {}\".format(i, Validationloss))\n",
    "            if i == 500:\n",
    "                lowestValidationLoss = Validationloss\n",
    "            \n",
    "                f=open(\"lowestValidationLoss.txt\", \"w\")\n",
    "                f.write(str(lowestValidationLoss))\n",
    "                f.close()\n",
    "            \n",
    "            if Validationloss < lowestValidationLoss:\n",
    "                lowestValidationLoss = Validationloss\n",
    "                f=open(\"lowestValidationLoss.txt\", \"w\")\n",
    "                f.write(str(lowestValidationLoss))\n",
    "                f.close()\n",
    "            \n",
    "                \n",
    "    #10% of the dataset - evaluation\n",
    "    matches = tf.equal(tf.argmax(outputPlacehlder,axis = 1), tf.argmax(predict,axis = 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(matches, tf.float32))\n",
    "    print(matches)\n",
    "    feed_test = {\n",
    "        inputPlaceholder: inputTest,\n",
    "        outputPlacehlder: outputTest\n",
    "    }\n",
    "\n",
    "    print(\"accuracy: {}\".format(sess.run(accuracy, feed_dict = feed_test) *100 ))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
